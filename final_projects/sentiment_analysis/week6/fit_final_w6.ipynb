{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка сентимент-анализа под задачу заказчика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.grid_search import RandomizedSearchCV \n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "import sys\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Парсим отзывы о смартфонах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсить будем https://technopoint.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile parser.py\n",
    "###### Собственно сам парсер. #######\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import requests\n",
    "import bs4 as bs4\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "def split_uppercase(string):\n",
    "    x = ''\n",
    "    k = 0\n",
    "    for c in string:\n",
    "        if k == 0:\n",
    "            x += c\n",
    "        elif c.isupper() and not string[k-1].isupper():\n",
    "            x += ' %s' % c\n",
    "        else:\n",
    "            x += c\n",
    "        k += 1\n",
    "\n",
    "    return x.strip()\n",
    "\n",
    "\n",
    "site = 'https://technopoint.ru'\n",
    "base_url = 'https://technopoint.ru/catalog/17a75b8e16404e77/smartfony'\n",
    "pages = []\n",
    "\n",
    "for p in range(1, 33):\n",
    "    pages.append(base_url + '/?p=' + str(p) + '&i=1&stock=0&order=4')\n",
    "\n",
    "products_link = []\n",
    "print \"Get Pages:\\n\"\n",
    "for page in tqdm(pages):\n",
    "    req = requests.get(page)\n",
    "    parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    links = parser.findAll('a', attrs={'data-role': 'product-cart-link'})\n",
    "    for link in links:\n",
    "        products_link.append(site + link['href'] + 'opinion/')\n",
    "\n",
    "\n",
    "print \"\\n\\nGet Pages With Comments:\\n\"\n",
    "pages_with_comments = []\n",
    "for link in tqdm(products_link):\n",
    "    req = requests.get(link)\n",
    "    parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    ul_pagination = parser.find('ul', {\"class\": \"pagination\"})\n",
    "    comments_pager_last_link = None\n",
    "    if ul_pagination is not None:\n",
    "        comments_pager_last_link = ul_pagination.find('li', {\"class\": \"last\"}).find('a')\n",
    "\n",
    "    comments_pages_count = 1\n",
    "    if comments_pager_last_link is not None:\n",
    "        comments_pages_count = int(comments_pager_last_link[\"data-page\"]) + 1\n",
    "\n",
    "    for page_with_comments in range(1, comments_pages_count + 1):\n",
    "        pages_with_comments.append(link + str(page_with_comments) + '/')\n",
    "\n",
    "i = 1\n",
    "print \"\\n\\nProceed Pages With Comments:\\n\"\n",
    "for page_with_comments in tqdm(pages_with_comments):\n",
    "    req = requests.get(page_with_comments)\n",
    "    parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    opinion_items = parser.find('div', {\"class\": \"opinion-container\"}).findAll('div', {\"class\": \"opinion-item\"})\n",
    "    for opinion_item in opinion_items:\n",
    "        description = str(opinion_item.find('div', {\"class\": \"descriptions\"})).replace(\"\\n\", ' ')\n",
    "        description = split_uppercase(unicode(description))\n",
    "\n",
    "        grade = opinion_item[\"data-grade\"]\n",
    "\n",
    "        comment_file = open('./data/' + str(i) + '.txt', 'w')\n",
    "        comment_file.write(page_with_comments + \"\\n\" + grade + \"\\n\" + description)\n",
    "        comment_file.close()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "print \"\\n\"\n",
    "print \"Total comments: \" + str(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсер только вытащил сырые комментарии с сайта и разложил в файлы. Теперь сформируем csv файл из комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile csv_creator.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import bs4 as bs4\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "path = './data'\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "texts = []\n",
    "grades = []\n",
    "links = []\n",
    "full_contents = []\n",
    "\n",
    "for file_name in tqdm(files):\n",
    "    f = open(path + '/' + file_name)\n",
    "    content = f.read()\n",
    "    link, grade, html = content.split(\"\\n\")\n",
    "\n",
    "    parser = bs4.BeautifulSoup(html, 'lxml')\n",
    "    lis = parser.findAll('li')\n",
    "\n",
    "    comment_text = ''\n",
    "    try:\n",
    "        if int(grade) in [4, 5]:\n",
    "            comment_text += lis[0].find('span', {'class': 'description-text'}).text\n",
    "        else:\n",
    "            comment_text += lis[1].find('span', {'class': 'description-text'}).text\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        comment_text += ' ' + lis[2].find('span', {'class': 'description-text'}).text\n",
    "    except (IndexError, AttributeError) as e:\n",
    "        pass\n",
    "\n",
    "    texts.append(comment_text)\n",
    "    links.append(link)\n",
    "    grades.append(grade)\n",
    "    full_contents.append(content)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['grade'] = grades\n",
    "data['link'] = links\n",
    "data['text'] = texts\n",
    "data['content'] = full_contents\n",
    "\n",
    "data.to_csv('./data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обрабатываем сырые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>https://technopoint.ru/product/42db0e393aab333...</td>\n",
       "      <td>большой экран, мощный аккумулятор, режим для ч...</td>\n",
       "      <td>https://technopoint.ru/product/42db0e393aab333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>https://technopoint.ru/product/da39313444f8333...</td>\n",
       "      <td>Телефоном пользуюсь немного и это скорее перв...</td>\n",
       "      <td>https://technopoint.ru/product/da39313444f8333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>https://technopoint.ru/product/44b2f37e4035333...</td>\n",
       "      <td>Цена, брал за 7900 руб.  Яркий экран, хорошо ...</td>\n",
       "      <td>https://technopoint.ru/product/44b2f37e4035333...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade                                               link  \\\n",
       "0      5  https://technopoint.ru/product/42db0e393aab333...   \n",
       "1      5  https://technopoint.ru/product/da39313444f8333...   \n",
       "2      4  https://technopoint.ru/product/44b2f37e4035333...   \n",
       "\n",
       "                                                text  \\\n",
       "0  большой экран, мощный аккумулятор, режим для ч...   \n",
       "1   Телефоном пользуюсь немного и это скорее перв...   \n",
       "2   Цена, брал за 7900 руб.  Яркий экран, хорошо ...   \n",
       "\n",
       "                                             content  \n",
       "0  https://technopoint.ru/product/42db0e393aab333...  \n",
       "1  https://technopoint.ru/product/da39313444f8333...  \n",
       "2  https://technopoint.ru/product/44b2f37e4035333...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/data.csv')\n",
    "del data['Unnamed: 0']\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    8766\n",
       "4    2408\n",
       "3    1060\n",
       "1     652\n",
       "2     640\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11174\n",
       "0     2352\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = data.grade.apply(lambda x: 0 if x < 4 else 1)\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2424\n",
       "0    2352\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = data[['text', 'label']]\n",
    "drop_indices = np.random.choice(corpus[corpus.label == 1].index, 8750, replace=False)\n",
    "corpus = corpus.drop(drop_indices)\n",
    "corpus.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это функция для обработки строки. На выходе имеем чистую строку из нормализированных слов.\n",
    "\n",
    "def clean_str(string):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    symbols = [\n",
    "        ',', '.', '-', '*', '#', ')', '(', '/', '<', '>', ':', '+', '?', '!', '\"', '\"', '%', '=', '\\\\', '}'\n",
    "    ]\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        string = str(string).replace(symbol, ' ')\n",
    "        \n",
    "    words = string.split()\n",
    "    normalized_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        normalized_words.append(morph.parse(unicode(word.strip()))[0].normal_form)\n",
    "        \n",
    "    string = unicode(' '.join(normalized_words))\n",
    "    \n",
    "    return string\n",
    "\n",
    "corpus['text'] = corpus.text.apply(clean_str)\n",
    "corpus.to_csv('./data/data_morph.csv', encoding='utf-8') # Запишем данные так как процедура длительная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Строим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>пользоваться телефон 4 месяц не однократно лов...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>отвратительный оболочка от samsung на android ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>отличный материал изготовление качественный сб...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  пользоваться телефон 4 месяц не однократно лов...      0\n",
       "1  отвратительный оболочка от samsung на android ...      0\n",
       "2  отличный материал изготовление качественный сб...      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('./data/data_morph.csv')\n",
    "del corpus['Unnamed: 0']\n",
    "corpus.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем наилучшие параметры по сетке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897403685092128"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(corpus.label, n_folds=10, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='word')),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline_params = {\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'vectorizer__stop_words': [stopwords.words('russian'), None],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "    'vectorizer__norm': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "\n",
    "grid.fit(corpus.text.values.astype('U'), corpus.label)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + LogisticRegression): {}, params {}\" . format(grid.best_score_, grid.best_params_)\n",
    ")\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем конечную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 3), analyzer='word' ,stop_words=stopwords.words('russian'), norm='l2'\n",
    ")\n",
    "X_vect = vectorizer.fit_transform(corpus.text.values.astype('U'))\n",
    "\n",
    "classifier = LogisticRegression(penalty='l2')\n",
    "fitted = classifier.fit(X_vect, corpus.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Используем модель. Получаем предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('./data/test_data_to_predict.csv')\n",
    "data_test['text'] = data_test.text.apply(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_to_predict = data_test.text.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.transform(texts_to_predict)\n",
    "predicts = fitted.predict(X_test)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['Id'] = range(0,100)\n",
    "result['y'] = predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['y'] = result.y.apply(lambda x: 'neg' if x == 0 else 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    y\n",
       "0   0  neg\n",
       "1   1  pos\n",
       "2   2  neg\n",
       "3   3  neg\n",
       "4   4  pos"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('./data/result.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
