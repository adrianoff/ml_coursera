{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка сентимент-анализа под задачу заказчика\n",
    "К вашей компании пришел заказчик, которому нужно решение задачи анализа тональности отзывов на товары. Заказчик хочет, чтобы вы оценили возможное качество работы такого алгоритма на небольшой тестовой выборке. При этом больше никаких данных вам не предоставляется. Требуется, чтобы качество работы вашего алгоритма (по accuracy) было строго больше 85%.\n",
    "Оценка качества в этом задании реализована через контест на Kaggle Inclass:\n",
    "https://inclass.kaggle.com/c/product-reviews-sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг\n",
    "Отзывы и оценки будем парсить с сайта https://torg.mail.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "data = []\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('reviews_train.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow((data[0], data[1]))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    ads = soup.find_all('div', class_='review-item__body')\n",
    "    for ad in ads:\n",
    "        try:\n",
    "            review = ad.find('div', class_='review-item__content').text.strip()\n",
    "        except:\n",
    "            review = ''\n",
    "        try:\n",
    "            rating = ad.find('span', class_='review-item__rating-counter').text.strip()\n",
    "        except:\n",
    "            rating = ''\n",
    "\n",
    "        data = [review.encode('utf8'), rating]\n",
    "        write_csv(data)\n",
    "      \n",
    "\n",
    "base_url = 'https://torg.mail.ru/review/goods/mobilephones/?page='\n",
    "\n",
    "\n",
    "for i in range(1, 881):\n",
    "    url_gen = base_url + str(i)\n",
    "    html = get_html(url_gen)\n",
    "    get_page_data(html)\n",
    "\n",
    "# Чтобы не забанили используем случайную задержку между скачиванием страниц\n",
    "    sleep(randint(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получаем файл reviews_train.csv, содержащий отзывы на телефоны и оценки, выставленные покупателями от 0 до 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('reviews_train.csv',',', header=None)\n",
    "data.columns = ['text','rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      7701\n",
       "4,5    3690\n",
       "4      2422\n",
       "3      1179\n",
       "3,5     922\n",
       "1       898\n",
       "2       350\n",
       "2,5     340\n",
       "1,5      94\n",
       "0         4\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать негативными отзывы от 1 до 3, позитывными отзывы с 5 баллами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['res'] = 'NaN'\n",
    "for i in range(len(data)):\n",
    "    if data['rating'][i] == '1' or data['rating'][i] == '1,5' or data['rating'][i] == '2' or data['rating'][i] == '2,5' or data['rating'][i] == '3': \n",
    "        data['res'][i] = 0\n",
    "    else:\n",
    "        data['res'][i] = 'NaN'\n",
    "    if data['rating'][i] == '5': \n",
    "        data['res'][i] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      7701\n",
       "NaN    7038\n",
       "0      2861\n",
       "Name: res, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = data[data['res']==1]\n",
    "data0 = data[data['res']==0]\n",
    "data3 = pd.concat([data0, data1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_utf8 = data3['text']\n",
    "res = list(data3['res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Преобразуем из utf8 в unicode\n",
    "text_unicode = []\n",
    "for row in text_utf8:\n",
    "    text_unicode.append(row.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Чистим текст от небуквенных символов\n",
    "import re\n",
    "\n",
    "textr=[]\n",
    "for row in text_unicode:\n",
    "    textr.append(re.sub('[\\n\\t\\r\\s]',' ', row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Чистим от лишних пробелов\n",
    "text = []\n",
    "for row in textr:\n",
    "    text.append(re.sub(r'\\s+', ' ', row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Компания сделала шаг назад выпустив такуюмодель. Следующий смартфон у меня будет явно не ASUS Достоинства Большая батарея, 4G, wi-fi, android 7. Недостатки Плохое стекло, большой экран,один слот под симку или карту памяти, нест стабилизации при фотосъемке, качество фото среднее.\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим что получилось\n",
    "print text[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбираем модель\n",
    "\n",
    "Составим baseline из CountVectorizer, TfidfTransformer и классификаторов, встречавшихся ранее в курсе с параметрами по умолчанию. Посчитаем accuracy и выберем модели для дальнейшей оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  25 out of  25 | elapsed:  1.8min finished\n",
      "/Users/rusa/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.82002, std: 0.03066, params: {'classifier': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)},\n",
       " mean: 0.82323, std: 0.03691, params: {'classifier': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=2, tol=0.0001,\n",
       "     verbose=0)},\n",
       " mean: 0.82873, std: 0.03646, params: {'classifier': SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=2, shuffle=True, verbose=0,\n",
       "       warm_start=False)},\n",
       " mean: 0.72912, std: 0.00009, params: {'classifier': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=2, shrinking=True,\n",
       "  tol=0.001, verbose=False)},\n",
       " mean: 0.73196, std: 0.00102, params: {'classifier': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = 2\n",
    "\n",
    "parameters = {'classifier': [\n",
    "    LogisticRegression(random_state=rs), \n",
    "    LinearSVC(random_state=rs), \n",
    "    SGDClassifier(random_state=rs),  \n",
    "    SVC(random_state=rs),\n",
    "    MultinomialNB(),   \n",
    "    ]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('transformer', TfidfTransformer()),\n",
    "    ('classifier',  LogisticRegression(random_state=rs))\n",
    "    ])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', verbose=True, n_jobs=5)\n",
    "grid_search.fit(text, res)\n",
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем те, у которых accuracy > 0.82, это LogisticRegression, LinearSVC, SGDClassifier. Далее будем подбирать для них параметры.\n",
    "Внимание! Считается очень долго!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=5)]: Done 790 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=5)]: Done 1240 tasks      | elapsed: 77.8min\n",
      "[Parallel(n_jobs=5)]: Done 1790 tasks      | elapsed: 117.0min\n",
      "[Parallel(n_jobs=5)]: Done 2440 tasks      | elapsed: 157.6min\n",
      "[Parallel(n_jobs=5)]: Done 3190 tasks      | elapsed: 206.7min\n",
      "[Parallel(n_jobs=5)]: Done 4040 tasks      | elapsed: 261.3min\n",
      "[Parallel(n_jobs=5)]: Done 4990 tasks      | elapsed: 322.2min\n",
      "[Parallel(n_jobs=5)]: Done 6040 tasks      | elapsed: 388.9min\n",
      "[Parallel(n_jobs=5)]: Done 7190 tasks      | elapsed: 464.2min\n",
      "[Parallel(n_jobs=5)]: Done 8440 tasks      | elapsed: 544.4min\n",
      "[Parallel(n_jobs=5)]: Done 9790 tasks      | elapsed: 632.8min\n",
      "[Parallel(n_jobs=5)]: Done 11240 tasks      | elapsed: 728.0min\n",
      "[Parallel(n_jobs=5)]: Done 11520 out of 11520 | elapsed: 746.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844442340466\n",
      "{'vectorizer__ngram_range': (1, 2), 'classifier__max_iter': 10, 'vectorizer__max_df': 0.75, 'transformer__sublinear_tf': True, 'transformer__smooth_idf': True, 'transformer__use_idf': True, 'classifier__C': 15.0}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "               'vectorizer__ngram_range': [(1, 2), (1, 3)],\n",
    "               'vectorizer__max_df': [0.60, 0.65, 0.70, 0.75],\n",
    "    \n",
    "               'transformer__use_idf': [False, True],\n",
    "               'transformer__smooth_idf': [False, True],\n",
    "               'transformer__sublinear_tf': [False, True],\n",
    "                                  \n",
    "               'classifier__max_iter': [5, 10, 11, 12, 13, 15],\n",
    "               'classifier__C': [1.0, 3.0, 5.0, 10.0, 15.0, 20.0]\n",
    "              }\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('transformer', TfidfTransformer()),\n",
    "    ('classifier',  LogisticRegression(random_state=rs))\n",
    "    ])\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', verbose=True, n_jobs=5)\n",
    "grid_search.fit(text, res)\n",
    "print grid_search.best_score_\n",
    "print grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=5)]: Done 790 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=5)]: Done 960 out of 960 | elapsed: 61.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847945464874\n",
      "{'vectorizer__ngram_range': (1, 3), 'vectorizer__max_df': 0.75, 'transformer__sublinear_tf': True, 'transformer__smooth_idf': True, 'transformer__use_idf': True, 'classifier__C': 5.0}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "               'vectorizer__ngram_range': [(1, 2), (1, 3)],\n",
    "               'vectorizer__max_df': [0.60, 0.65, 0.70, 0.75],\n",
    "               \n",
    "               'transformer__use_idf': [False, True],\n",
    "               'transformer__smooth_idf': [False, True],\n",
    "               'transformer__sublinear_tf': [False, True],\n",
    "                         \n",
    "               'classifier__C' : [1.0, 3.0, 5.0]\n",
    "              }\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('transformer', TfidfTransformer()),\n",
    "    ('classifier',  LinearSVC(random_state=rs))\n",
    "    ])\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', verbose=True, n_jobs=5)\n",
    "grid_search.fit(text, res)\n",
    "print grid_search.best_score_\n",
    "print grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=5)]: Done 790 tasks      | elapsed: 53.3min\n",
      "[Parallel(n_jobs=5)]: Done 1240 tasks      | elapsed: 92.8min\n",
      "[Parallel(n_jobs=5)]: Done 1790 tasks      | elapsed: 158.8min\n",
      "[Parallel(n_jobs=5)]: Done 2440 tasks      | elapsed: 204.5min\n",
      "[Parallel(n_jobs=5)]: Done 3190 tasks      | elapsed: 294.3min\n",
      "[Parallel(n_jobs=5)]: Done 3200 out of 3200 | elapsed: 295.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850123082749\n",
      "{'vectorizer__ngram_range': (1, 2), 'classifier__alpha': 0.0001, 'vectorizer__max_features': None, 'vectorizer__max_df': 0.75, 'classifier__n_iter': 100, 'transformer__sublinear_tf': False, 'transformer__smooth_idf': False, 'transformer__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "               'vectorizer__max_features': [None],\n",
    "               'vectorizer__ngram_range': [(1, 2), (1, 3)],\n",
    "               'vectorizer__max_df': [0.60, 0.65, 0.70, 0.75],\n",
    "    \n",
    "               'transformer__use_idf': [False, True],\n",
    "               'transformer__smooth_idf': [False, True],\n",
    "               'transformer__sublinear_tf': [False, True],\n",
    "            \n",
    "               'classifier__alpha': [1e-4, 1e-5],\n",
    "               'classifier__n_iter': [5, 50, 100, 500, 1000]\n",
    "              }\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('transformer', TfidfTransformer()),\n",
    "    ('classifier',  SGDClassifier(random_state=rs))\n",
    "    ])\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', verbose=True, n_jobs=5)\n",
    "grid_search.fit(text, res)\n",
    "print grid_search.best_score_\n",
    "print grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинго!\n",
    "\n",
    "Наилучший результат 0.85 показал алгоритм с SGDClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Учим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "   ...      penalty='l2', power_t=0.5, random_state=2, shuffle=True, verbose=0,\n",
       "       warm_start=False))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1,2), max_df=0.75)),\n",
    "    ('transformer', TfidfTransformer(use_idf=True, smooth_idf=False, sublinear_tf=False)),\n",
    "    ('classifier',  SGDClassifier(random_state=rs, alpha=1e-4, n_iter=100,))\n",
    "    ])\n",
    "pipeline.fit(text,res)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Загружаем test отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "f = open(\"sss.xml\",'w')\n",
    "f.write('<root>\\n')\n",
    "f2 = open('test.csv','r')\n",
    "lines = f2.readlines()\n",
    "\n",
    "for line in lines: \n",
    "    f.write(line)\n",
    "f2.close()\n",
    "f.write('</root>')\n",
    "f.close()\n",
    "\n",
    "f = open('sss.xml', 'r')\n",
    "xml = etree.parse(f)\n",
    "test = xml.findall('review')\n",
    "test_unicode = [t.text for t in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Чистим текст от небуквенных символов\n",
    "import re\n",
    "\n",
    "testr=[]\n",
    "for row in test_unicode:\n",
    "    testr.append(re.sub('[\\n\\t\\r\\s]',' ', row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Чистим от лишних пробелов\n",
    "test=[]\n",
    "for row in testr:\n",
    "    test.append(re.sub(r'\\s+', ' ', row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метттлленнныййй-ммеееттлленный. Ну что это такое, невозможно просто выключить калькулятор, тел. спрашивает меня, уверена ли я, закрыть ли приложение? А потом долго показывает кружочек, закрываю-де, сейчас-сейчас! Долго включается-загружается. Это что у меня, перегруженный смартфон с десятью фильмами на борту, или элементарный простой телефон? Меньше года в работе, стал на исходящие вызовы показывать мне \"вызов запрещен\", лечится перезагрузкой. КЕМ запрещен??????? Игр не стоит, фоток минимум, в интернет не ходила. Очень тупой, неудобный, я НЕ довольна, почти за год так и не привыкла, только стал больше раздражать. Набирать номер не удобно. После перезагрузки ненормально долго \"список контактов недоступен\", не позвонить. Кажется, что прием сигнала чаще, чем нужно, падает. Оставлю отзыв, поскольку телефон еще продается. \n"
     ]
    }
   ],
   "source": [
    "print test[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(pipeline.predict(test), columns=['y1'])\n",
    "result.index.name='Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rusa/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем к тербуемому формату ответа\n",
    "\n",
    "result['y'] = 'neg'\n",
    "result['y'][result['y1']==1]='pos'\n",
    "result = result.drop(['y1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,y\r\n",
      "0,neg\r\n",
      "1,pos\r\n",
      "2,neg\r\n",
      "3,neg\r\n",
      "4,pos\r\n",
      "5,pos\r\n",
      "6,pos\r\n",
      "7,pos\r\n",
      "8,neg\r\n",
      "9,pos\r\n",
      "10,neg\r\n",
      "11,pos\r\n",
      "12,pos\r\n",
      "13,pos\r\n",
      "14,pos\r\n",
      "15,pos\r\n",
      "16,pos\r\n",
      "17,pos\r\n",
      "18,pos\r\n",
      "19,pos\r\n",
      "20,pos\r\n",
      "21,neg\r\n",
      "22,neg\r\n",
      "23,pos\r\n",
      "24,pos\r\n",
      "25,neg\r\n",
      "26,pos\r\n",
      "27,pos\r\n",
      "28,neg\r\n",
      "29,pos\r\n",
      "30,neg\r\n",
      "31,pos\r\n",
      "32,neg\r\n",
      "33,pos\r\n",
      "34,neg\r\n",
      "35,pos\r\n",
      "36,pos\r\n",
      "37,pos\r\n",
      "38,pos\r\n",
      "39,pos\r\n",
      "40,pos\r\n",
      "41,pos\r\n",
      "42,pos\r\n",
      "43,neg\r\n",
      "44,neg\r\n",
      "45,pos\r\n",
      "46,pos\r\n",
      "47,pos\r\n",
      "48,neg\r\n",
      "49,neg\r\n",
      "50,neg\r\n",
      "51,neg\r\n",
      "52,neg\r\n",
      "53,neg\r\n",
      "54,neg\r\n",
      "55,pos\r\n",
      "56,pos\r\n",
      "57,pos\r\n",
      "58,pos\r\n",
      "59,pos\r\n",
      "60,neg\r\n",
      "61,pos\r\n",
      "62,neg\r\n",
      "63,neg\r\n",
      "64,neg\r\n",
      "65,neg\r\n",
      "66,neg\r\n",
      "67,neg\r\n",
      "68,pos\r\n",
      "69,pos\r\n",
      "70,pos\r\n",
      "71,neg\r\n",
      "72,neg\r\n",
      "73,neg\r\n",
      "74,pos\r\n",
      "75,pos\r\n",
      "76,neg\r\n",
      "77,pos\r\n",
      "78,neg\r\n",
      "79,neg\r\n",
      "80,neg\r\n",
      "81,pos\r\n",
      "82,neg\r\n",
      "83,pos\r\n",
      "84,pos\r\n",
      "85,pos\r\n",
      "86,pos\r\n",
      "87,pos\r\n",
      "88,neg\r\n",
      "89,neg\r\n",
      "90,pos\r\n",
      "91,pos\r\n",
      "92,neg\r\n",
      "93,pos\r\n",
      "94,neg\r\n",
      "95,pos\r\n",
      "96,pos\r\n",
      "97,neg\r\n",
      "98,pos\r\n",
      "99,pos\r\n"
     ]
    }
   ],
   "source": [
    "result1.to_csv('result.csv', sep=',', header=True, index=True)\n",
    "!cat result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Загружаем на https://inclass.kaggle.com/c/product-reviews-sentiment-analysis   Результат 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
