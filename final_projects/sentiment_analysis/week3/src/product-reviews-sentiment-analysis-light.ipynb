{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer-graded Assignment: Соревнование по сентимент-анализу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.grid_search import RandomizedSearchCV \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_table('../data/products_sentiment_train.tsv', header=None, index_col=False)\n",
    "data_test = pd.read_table('../data/products_sentiment_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Даем название колонкам\n",
    "\n",
    "data_train['text'] = data_train[0]\n",
    "data_train['label'] = data_train[1]\n",
    "del data_train[0]\n",
    "del data_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Осмотрим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text\n",
       "0   0  so , why the small digital elph , rather than ...\n",
       "1   1  3/4 way through the first disk we played on it...\n",
       "2   2  better for the zen micro is outlook compatibil...\n",
       "3   3    6 . play gameboy color games on it with goboy .\n",
       "4   4  likewise , i 've heard norton 2004 professiona..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>249.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>124.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>249.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>374.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>499.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id\n",
       "count  500.000000\n",
       "mean   249.500000\n",
       "std    144.481833\n",
       "min      0.000000\n",
       "25%    124.750000\n",
       "50%    249.500000\n",
       "75%    374.250000\n",
       "max    499.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  2000.000000\n",
       "mean      0.637000\n",
       "std       0.480985\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1274\n",
       "0     726\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор лучшей модели\n",
    "С помощью Pipiline и GridSearchCV переберем модели и выберем лучшую. Чтобы избежать переобучения воспользуемся StratifiedKFold.\n",
    "\n",
    "##### Попробуем 4 метода:\n",
    "LogisticRegression\n",
    "\n",
    "SGDClassifier\n",
    "\n",
    "LinearSVC\n",
    "\n",
    "MultinomialNB\n",
    "\n",
    "##### и преобразование для текста: TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train['text']\n",
    "y = data_train['label']\n",
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6000 candidates, totalling 60000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=4)]: Done 9792 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=4)]: Done 11242 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=4)]: Done 12792 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=4)]: Done 14442 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=4)]: Done 16192 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=4)]: Done 18042 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=4)]: Done 19992 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=4)]: Done 22042 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=4)]: Done 24192 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=4)]: Done 26442 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=4)]: Done 28792 tasks      | elapsed: 51.4min\n",
      "[Parallel(n_jobs=4)]: Done 31242 tasks      | elapsed: 56.3min\n",
      "[Parallel(n_jobs=4)]: Done 33792 tasks      | elapsed: 59.4min\n",
      "[Parallel(n_jobs=4)]: Done 36442 tasks      | elapsed: 65.9min\n",
      "[Parallel(n_jobs=4)]: Done 39192 tasks      | elapsed: 70.5min\n",
      "[Parallel(n_jobs=4)]: Done 42042 tasks      | elapsed: 73.9min\n",
      "[Parallel(n_jobs=4)]: Done 44992 tasks      | elapsed: 78.3min\n",
      "[Parallel(n_jobs=4)]: Done 48042 tasks      | elapsed: 82.2min\n",
      "[Parallel(n_jobs=4)]: Done 51192 tasks      | elapsed: 86.3min\n",
      "[Parallel(n_jobs=4)]: Done 54442 tasks      | elapsed: 91.8min\n",
      "[Parallel(n_jobs=4)]: Done 57792 tasks      | elapsed: 97.2min\n",
      "[Parallel(n_jobs=4)]: Done 60000 out of 60000 | elapsed: 100.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + LogisticRegression): 0.7875, params {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_features': None, 'vectorizer__use_idf': True, 'vectorizer__norm': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__analyzer': 'word', 'vectorizer__stop_words': None, 'classifier__C': 100, 'classifier__penalty': 'l2'}\n",
      "CPU times: user 4min 49s, sys: 8.71 s, total: 4min 57s\n",
      "Wall time: 1h 40min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()), (\"classifier\", LogisticRegression())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'vectorizer__stop_words': ['english', None],\n",
    "        'vectorizer__ngram_range': [(1, 2), (1, 3), (2, 3), (3, 5), (4, 5), (2, 5)],\n",
    "        'vectorizer__analyzer': ['word', 'char_wb'],\n",
    "        'vectorizer__norm': ['l1', 'l2', None],\n",
    "        'vectorizer__use_idf': (True, False),\n",
    "        'vectorizer__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'vectorizer__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "        'classifier__C': [0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=6000)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + LogisticRegression): {}, params {}\" . format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 600 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=4)]: Done 9000 out of 9000 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + SGDClassifier): 0.7845 with params {'tfidf__smooth_idf': True, 'sgd__alpha': 1e-06, 'tfidf__ngram_range': (1, 4), 'sgd__penalty': 'elasticnet', 'tfidf__max_features': None, 'tfidf__stop_words': None, 'tfidf__max_df': 1.0, 'tfidf__use_idf': True, 'tfidf__norm': 'l1', 'sgd__loss': 'hinge'}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(y, n_folds=15, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('sgd', SGDClassifier())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'tfidf__ngram_range': [(1, 3), (1, 4)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'tfidf__smooth_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2', None),\n",
    "        \"sgd__penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "        \"sgd__loss\": ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'sgd__alpha': (0.00001, 0.000001)\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=600)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\"Accuracy (TfidfVectorizer + SGDClassifier): {} with params {}\"\n",
    "      .format(grid.best_score_, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + SGDClassifier): 0.7675 with params {'tfidf__smooth_idf': True, 'rf__n_estimators': 1000, 'tfidf__ngram_range': (1, 3), 'tfidf__max_features': 1000, 'tfidf__max_df': 0.25, 'rf__min_samples_split': 6, 'tfidf__use_idf': False, 'rf__min_samples_leaf': 1, 'tfidf__norm': None}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "pipeline_params = {\n",
    "        'tfidf__ngram_range': [(1, 3)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'tfidf__smooth_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2', None),\n",
    "        \"rf__n_estimators\": [1000, 1500],\n",
    "        \"rf__min_samples_split\": [6, 8, 10],\n",
    "        \"rf__min_samples_leaf\": [1, 2, 4]\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=30)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\"Accuracy (TfidfVectorizer + SGDClassifier): {} with params {}\"\n",
    "      .format(grid.best_score_, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   48.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + MLPClassifier): 0.768 with params {'tfidf__ngram_range': (1, 3)}\n",
      "CPU times: user 13.6 s, sys: 800 ms, total: 14.4 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(10,)))\n",
    "])\n",
    "pipeline_params = {\n",
    "        'tfidf__ngram_range': [(1, 3)],\n",
    "        #'tfidf__use_idf': (True, False),\n",
    "        #'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        #'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        #'tfidf__smooth_idf': (True, False),\n",
    "        #'tfidf__norm': ('l1', 'l2', None),\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "#grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=1)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + MLPClassifier): {} with params {}\".format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 336 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 1680 out of 1680 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + MLPClassifier): 0.743 with params {'tfidf__smooth_idf': False, 'tfidf__ngram_range': (1, 3), 'tfidf__max_features': 500, 'tfidf__max_df': 0.25, 'tfidf__use_idf': True, 'tfidf__norm': None}\n",
      "CPU times: user 8.58 s, sys: 288 ms, total: 8.86 s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'tfidf__ngram_range': [(1, 3)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'tfidf__smooth_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2', None),\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "#grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=1)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + MLPClassifier): {} with params {}\".format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 336 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1680 out of 1680 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + MLPClassifier): 0.776 with params {'tfidf__smooth_idf': True, 'tfidf__ngram_range': (1, 3), 'tfidf__max_features': None, 'tfidf__max_df': 0.25, 'tfidf__use_idf': False, 'tfidf__norm': None}\n",
      "CPU times: user 8.04 s, sys: 240 ms, total: 8.28 s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cv = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svc', MultinomialNB())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'tfidf__ngram_range': [(1, 3)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'tfidf__smooth_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2', None),\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "#grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=1)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + MLPClassifier): {} with params {}\".format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
