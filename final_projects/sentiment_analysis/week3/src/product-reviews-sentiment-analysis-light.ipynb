{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer-graded Assignment: Соревнование по сентимент-анализу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/local/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.grid_search import RandomizedSearchCV \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_table('../data/products_sentiment_train.tsv', header=None, index_col=False)\n",
    "data_test = pd.read_table('../data/products_sentiment_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Даем название колонкам\n",
    "\n",
    "data_train['text'] = data_train[0]\n",
    "data_train['label'] = data_train[1]\n",
    "del data_train[0]\n",
    "del data_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Осмотрим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text\n",
       "0   0  so , why the small digital elph , rather than ...\n",
       "1   1  3/4 way through the first disk we played on it...\n",
       "2   2  better for the zen micro is outlook compatibil...\n",
       "3   3    6 . play gameboy color games on it with goboy .\n",
       "4   4  likewise , i 've heard norton 2004 professiona..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>249.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>124.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>249.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>374.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>499.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id\n",
       "count  500.000000\n",
       "mean   249.500000\n",
       "std    144.481833\n",
       "min      0.000000\n",
       "25%    124.750000\n",
       "50%    249.500000\n",
       "75%    374.250000\n",
       "max    499.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  2000.000000\n",
       "mean      0.637000\n",
       "std       0.480985\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1274\n",
       "0     726\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор лучшей модели\n",
    "С помощью Pipiline и GridSearchCV переберем модели и выберем лучшую. Чтобы избежать переобучения воспользуемся StratifiedKFold.\n",
    "\n",
    "##### Попробуем 4 метода:\n",
    "LogisticRegression\n",
    "\n",
    "SGDClassifier\n",
    "\n",
    "LinearSVC\n",
    "\n",
    "MultinomialNB\n",
    "\n",
    "##### и преобразование для текста: TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_train['text']\n",
    "y = data_train['label']\n",
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization_data(data):\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    tokens_list = [nltk.word_tokenize(raw) for raw in data]\n",
    "    for tokens in tokens_list:\n",
    "        tokens = [wnl.lemmatize(t) for t in tokens]\n",
    "        \n",
    "    data_processing = [' '.join(x) for x in tokens_list]\n",
    "    return data_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пробуем LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 600 out of 600 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + LogisticRegression): 0.781, params {'vectorizer__ngram_range': (4, 5), 'vectorizer__max_features': None, 'vectorizer__use_idf': True, 'vectorizer__norm': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__analyzer': 'char_wb', 'vectorizer__stop_words': None, 'classifier__C': 10, 'classifier__penalty': 'l2'}\n",
      "CPU times: user 13.9 s, sys: 1.69 s, total: 15.5 s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()), (\"classifier\", LogisticRegression())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'vectorizer__stop_words': ['english', None],\n",
    "        'vectorizer__ngram_range': [(1, 2), (1, 3), (2, 3), (3, 5), (4, 5), (2, 5)],\n",
    "        'vectorizer__analyzer': ['word', 'char_wb'],\n",
    "        'vectorizer__norm': ['l1', 'l2', None],\n",
    "        'vectorizer__use_idf': (True, False),\n",
    "        'vectorizer__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'vectorizer__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "        'classifier__C': [0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=60)\n",
    "grid.fit(lemmatization_data(X), y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + LogisticRegression): {}, params {}\" . format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пробуем SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6000 candidates, totalling 60000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=4)]: Done 9792 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=4)]: Done 11242 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=4)]: Done 12792 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=4)]: Done 14442 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=4)]: Done 16192 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=4)]: Done 18042 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=4)]: Done 19992 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=4)]: Done 22042 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=4)]: Done 24192 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=4)]: Done 26442 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=4)]: Done 28792 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=4)]: Done 31242 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=4)]: Done 33792 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=4)]: Done 36442 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=4)]: Done 39192 tasks      | elapsed: 49.1min\n",
      "[Parallel(n_jobs=4)]: Done 42042 tasks      | elapsed: 52.5min\n",
      "[Parallel(n_jobs=4)]: Done 44992 tasks      | elapsed: 56.0min\n",
      "[Parallel(n_jobs=4)]: Done 48042 tasks      | elapsed: 59.8min\n",
      "[Parallel(n_jobs=4)]: Done 51192 tasks      | elapsed: 63.5min\n",
      "[Parallel(n_jobs=4)]: Done 54442 tasks      | elapsed: 67.4min\n",
      "[Parallel(n_jobs=4)]: Done 57792 tasks      | elapsed: 71.5min\n",
      "[Parallel(n_jobs=4)]: Done 60000 out of 60000 | elapsed: 74.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + SGDClassifier): 0.79 with params {'vectorizer__ngram_range': (2, 5), 'sgd__alpha': 0.001, 'vectorizer__max_features': None, 'vectorizer__use_idf': True, 'sgd__penalty': 'l2', 'vectorizer__analyzer': 'char_wb', 'vectorizer__max_df': 1.0, 'vectorizer__norm': 'l2', 'sgd__loss': 'hinge'}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', SGDClassifier())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'vectorizer__ngram_range': [(1, 2), (1, 3), (2, 3), (3, 5), (4, 5), (2, 5)],\n",
    "        'vectorizer__analyzer': ['word', 'char_wb'],\n",
    "        'vectorizer__norm': ['l1', 'l2', None],\n",
    "        'vectorizer__use_idf': (True, False),\n",
    "        'vectorizer__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'vectorizer__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        \"classifier__penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "        \"classifier__loss\": ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'classifier__alpha': (0.001, 0.0001, 0.00001, 0.000001)\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=6000)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + SGDClassifier): {}, params {}\".format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пробуем LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 600 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 57.4min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed: 86.6min\n",
      "[Parallel(n_jobs=4)]: Done 6000 out of 6000 | elapsed: 105.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + LinearSVC): 0.789, params {'vectorizer__ngram_range': (3, 5), 'vectorizer__max_features': None, 'vectorizer__use_idf': True, 'classifier__loss': 'hinge', 'vectorizer__analyzer': 'char_wb', 'vectorizer__max_df': 1.0, 'vectorizer__norm': 'l2', 'classifier__C': 0.5, 'classifier__multi_class': 'ovr', 'classifier__penalty': 'l2'}\n",
      "CPU times: user 1min 16s, sys: 12.8 s, total: 1min 28s\n",
      "Wall time: 1h 45min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LinearSVC())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'vectorizer__ngram_range': [(1, 2), (1, 3), (2, 3), (3, 5), (4, 5), (2, 5)],\n",
    "        'vectorizer__analyzer': ['word', 'char_wb'],\n",
    "        'vectorizer__norm': ['l1', 'l2', None],\n",
    "        'vectorizer__use_idf': (True, False),\n",
    "        'vectorizer__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'vectorizer__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        \"classifier__penalty\": ['l2'],\n",
    "        \"classifier__loss\": ['hinge'],\n",
    "        'classifier__C': [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "        'classifier__multi_class': ['ovr', 'crammer_singer'],\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=600)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + LinearSVC): {}, params {}\" . format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пробуем MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6000 candidates, totalling 60000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=4)]: Done 9792 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=4)]: Done 11242 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=4)]: Done 12792 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=4)]: Done 14442 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=4)]: Done 16192 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=4)]: Done 18042 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=4)]: Done 19992 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=4)]: Done 22042 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=4)]: Done 24192 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=4)]: Done 26442 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=4)]: Done 28792 tasks      | elapsed: 35.3min\n",
      "[Parallel(n_jobs=4)]: Done 31242 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=4)]: Done 33792 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=4)]: Done 36442 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=4)]: Done 39192 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=4)]: Done 42042 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=4)]: Done 44992 tasks      | elapsed: 54.3min\n",
      "[Parallel(n_jobs=4)]: Done 48042 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=4)]: Done 51192 tasks      | elapsed: 61.8min\n",
      "[Parallel(n_jobs=4)]: Done 54442 tasks      | elapsed: 65.7min\n",
      "[Parallel(n_jobs=4)]: Done 57792 tasks      | elapsed: 69.8min\n",
      "[Parallel(n_jobs=4)]: Done 60000 out of 60000 | elapsed: 72.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + MultinomialNB): 0.799, params {'vectorizer__ngram_range': (3, 5), 'classifier__alpha': 0.1, 'vectorizer__max_features': None, 'vectorizer__use_idf': False, 'vectorizer__analyzer': 'char_wb', 'vectorizer__max_df': 1.0, 'vectorizer__norm': 'l2', 'classifier__fit_prior': False}\n",
      "CPU times: user 4min 28s, sys: 6.66 s, total: 4min 34s\n",
      "Wall time: 1h 12min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'vectorizer__ngram_range': [(1, 2), (1, 3), (2, 3), (3, 5), (4, 5), (2, 5)],\n",
    "        'vectorizer__analyzer': ['word', 'char_wb'],\n",
    "        'vectorizer__norm': ['l1', 'l2', None],\n",
    "        'vectorizer__use_idf': (True, False),\n",
    "        'vectorizer__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'vectorizer__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        \"classifier__alpha\": [0.1, 0.5, 1.0],\n",
    "        \"classifier__fit_prior\": [True, False]\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=6000)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\n",
    "    \"Accuracy (TfidfVectorizer + MultinomialNB): {}, params {}\" . format(grid.best_score_, grid.best_params_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Наилучший результат показал MultinomialNB. С ним дальше и будем работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization_data(data):\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    tokens_list = [nltk.word_tokenize(raw) for raw in data]\n",
    "    for tokens in tokens_list:\n",
    "        tokens = [wnl.lemmatize(t) for t in tokens]\n",
    "        \n",
    "    data_processing = [' '.join(x) for x in tokens_list]\n",
    "    return data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'the instructions' u'still hard' u'reading some' u'reading some of'\n",
      " u'hard to figure' u'even after reading' u'the instructions it'\n",
      " u'instructions it still' u'of the instructions' u'still hard to']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 3), max_df=1.0, analyzer='word', use_idf=True,\n",
    "    norm='l2'\n",
    ")\n",
    "X_vect = vectorizer.fit_transform(lemmatization_data(X))\n",
    "\n",
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "tfidf_sorting = np.argsort(X_vect.toarray()).flatten()[::-1]\n",
    "n = 10\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "\n",
    "#Выведем топ 10 слов\n",
    "print top_n\n",
    "\n",
    "\n",
    "classifier = MultinomialNB(alpha=0.1, fit_prior=False)\n",
    "\n",
    "X_test = vectorizer.transform(lemmatization_data(data_test.text))\n",
    "predicts = classifier.fit(X_vect, y).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  y\n",
       "0   0  1\n",
       "1   1  0\n",
       "2   2  1\n",
       "3   3  1\n",
       "4   4  0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = data_test.Id\n",
    "submission['y'] = predicts\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../data/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На kaggle получили 0.78750. Хотелось бы узнать как значительно улучшить результ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
