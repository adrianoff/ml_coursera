{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_table('../data/products_sentiment_train.tsv', header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train['text'] = data_train[0]\n",
    "data_train['label'] = data_train[1]\n",
    "del data_train[0]\n",
    "del data_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  2000.000000\n",
       "mean      0.637000\n",
       "std       0.480985\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1274\n",
       "0     726\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_train['text']\n",
    "y = data_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "X_vect = count_vectorizer.fit_transform(X).toarray()\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(estimator=estimator, X=X_vect, y=y, cv=20)\n",
    "print round(scores.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 192 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done 286 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=4)]: Done 536 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=4)]: Done 886 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1336 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 1886 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 2536 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 2880 out of 2880 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CountVectorizer + LogisticRegression): 0.7785 with params {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 2), 'classifier__C': 0.5, 'vectorizer__analyzer': 'word', 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(y, n_folds=15, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()), (\"classifier\", LogisticRegression())\n",
    "])\n",
    "pipeline_params = [\n",
    "    {\n",
    "        \"vectorizer__stop_words\": ['english', None],\n",
    "        \"vectorizer__ngram_range\": [(1, 2), (1, 3), (2, 3), (3, 5), (4, 5), (2, 5)],\n",
    "        \"vectorizer__analyzer\": ['word', 'char_wb'],\n",
    "        \"classifier__penalty\": ['l1', 'l2'],\n",
    "        \"classifier__C\": [0.5, 1, 5, 10]\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\"Accuracy (CountVectorizer + LogisticRegression): {} with params {}\"\n",
    "      .format(grid.best_score_, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 600 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=4)]: Done 9000 out of 9000 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + SGDClassifier): 0.7845 with params {'tfidf__smooth_idf': True, 'sgd__alpha': 1e-06, 'tfidf__ngram_range': (1, 4), 'sgd__penalty': 'elasticnet', 'tfidf__max_features': None, 'tfidf__stop_words': None, 'tfidf__max_df': 1.0, 'tfidf__use_idf': True, 'tfidf__norm': 'l1', 'sgd__loss': 'hinge'}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(y, n_folds=15, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('sgd', SGDClassifier())\n",
    "])\n",
    "pipeline_params = {\n",
    "        'tfidf__ngram_range': [(1, 3), (1, 4)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'tfidf__stop_words': ('english', None),\n",
    "        'tfidf__smooth_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2', None),\n",
    "        \"sgd__penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "        \"sgd__loss\": ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'sgd__alpha': (0.00001, 0.000001)\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=600)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\"Accuracy (TfidfVectorizer + SGDClassifier): {} with params {}\"\n",
    "      .format(grid.best_score_, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TfidfVectorizer + SGDClassifier): 0.7675 with params {'tfidf__smooth_idf': True, 'rf__n_estimators': 1000, 'tfidf__ngram_range': (1, 3), 'tfidf__max_features': 1000, 'tfidf__max_df': 0.25, 'rf__min_samples_split': 6, 'tfidf__use_idf': False, 'rf__min_samples_leaf': 1, 'tfidf__norm': None}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=1))\n",
    "])\n",
    "pipeline_params = {\n",
    "        'tfidf__ngram_range': [(1, 3)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "        'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "        'tfidf__smooth_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2', None),\n",
    "        \"rf__n_estimators\": [1000, 1500],\n",
    "        \"rf__min_samples_split\": [6, 8, 10],\n",
    "        \"rf__min_samples_leaf\": [1, 2, 4]\n",
    "    }\n",
    "\n",
    "#grid = GridSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4)\n",
    "grid = RandomizedSearchCV(pipeline, pipeline_params, cv=cv, refit=True, verbose=1, n_jobs=4, n_iter=30)\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "print(\"Accuracy (TfidfVectorizer + SGDClassifier): {} with params {}\"\n",
    "      .format(grid.best_score_, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
